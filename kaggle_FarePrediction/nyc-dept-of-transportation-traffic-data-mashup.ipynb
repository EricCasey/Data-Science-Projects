{"cells":[{"metadata":{"_uuid":"f45631580f5c7d9a0f7afdd444772061fe5fc92d"},"cell_type":"markdown","source":"![img](https://i.imgur.com/ecEdqxY.jpg)\n"},{"metadata":{"_uuid":"00ebeab03acf468853c9794f0ade69e654fe7a1a"},"cell_type":"markdown","source":"Hey there, Eric here. \n\nI'm pretty new to R & ML in general. I dabbled with openCV in Node.JS but for this I'm winging it. \n\nIf you can dream it you can do it. \n\nBasically the stategy in this kernel is to use the start and end points from lots of taxi rides and lots of start and end points  [some kind of trip]  from the NYC Department of Transportation. I've made an attempt at a graphic to explain my thought process below (*note: I dropped the time_of_day from this, the DOT data is a floating timestamp).\n\n![](https://i.imgur.com/5zLDiT9.png)\n\n![](https://i.imgur.com/FsKEh1t.png)\n\nAs of Sept 14th this is stil a work in progress, if anyone reading this sees any brutal mistakes or if there are simpler ways of doing this please let me know :) \n\nAny help making document more terse would be appreciated.\n\n**HEADS UP** I haven't actually made the model any better using this datasource. I'm still playing with it. Best score is : 4.05078 (in another kernel, sans seed)\n\nSecond Dataset Source: \nhttps://data.cityofnewyork.us/Transportation/Real-Time-Traffic-Speed-Data/qkm5-nuaq\n\nA bit of research I did: \nhttps://en.wikipedia.org/wiki/Taximeter https://gis3.dot.ny.gov/html5viewer/?viewer=tdv https://www.autoinsurancecenter.com/traffic-accidents-in-new-york-city.htm https://www.mapsofworld.com/usa/states/new-york/new-york-maps/new-york-lat-long-map.jpg http://www.nyc.gov/html/dot/html/about/mobilityreport.shtml\n\nWebsite : https://www.casey.works\n\nGitHub : https://www.github.com/EricCasey\n\nTwitch : https://www.twitch.tv/casey_works\n"},{"metadata":{"_uuid":"7577686cd1e915353fe0df373a98933da9fc49b6"},"cell_type":"markdown","source":"**STEP 1** : Load Packages"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"946d197da909269a4defe5ae08b63caed7099ebd","_kg_hide-output":true},"cell_type":"code","source":"print(\"init\")\n\npacks <- c(\"tidyverse\", \"lubridate\", \"nFactors\", \"stringr\", \n           \"import\", \"glmnet\", \"readr\",  \"RSNNS\", \"plyr\", \n           \"dplyr\", \"caret\", \"beepr\", \"mgcv\", \"spls\", \"gbm\", \n           \"xgboost\", \"corrplot\", \"geosphere\", \"DMwR\" ,\"MuMIn\", \n           \"png\",\"grid\")\n\nlapply(packs, require, character.only = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"575d29a3f49002290a48029fbcdd9c5ffc75e1c8","_execution_state":"idle"},"cell_type":"markdown","source":"**STEP 2** : Some general config options"},{"metadata":{"trusted":true,"_uuid":"9caaf8cb3f112ba91d9f0759be620881101c03b2","_kg_hide-output":true},"cell_type":"code","source":"set.seed(42) # DON'T PANIC\noptions(na.action = \"na.fail\")\noptions(stringsAsFactors = FALSE)\n\n# train_rows_import <- 1000000 \n# dot_rows_import   <- 1000\n# train_rows_sample <- train_rows_import / 2\n# dot_rows_sample   <- dot_rows_import / 1.2\n\ntrain_rows_import <- 30000\ndot_rows_import   <- 1000\ntrain_rows_sample <- train_rows_import / 5\ndot_rows_sample   <- dot_rows_import / 5\n\n# train_folds <- 100\ntrain_folds <- 10\ntrain_depth <- 3\ntrain_repeats <- 5\ntrain_tuneLength <- 5\ntrain_trees <- 250\n\n# TODO : \"inclusive of tolls\"\n# TODO : Backwards trip strings?\n# TODO : Remove training oints in the water (IN PROGRESS)\n# TODO : RUSH HOUR var?\n# TODO : HOLIDAYS var?\n# TODO : Can I use all points in the line to make routes? mindblown.gif\n# TODO : What can I do with those polylines?\n# TODO : What about the boroughs?\n# TODO : TripStr match rate analysis\n# TODO : Add the test data to the training set? make lm, impute fares, train?","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ae9a6a802c23d20bd4165a15e151d6b31b64d2c"},"cell_type":"markdown","source":"**STEP 3** : I think this is filesize"},{"metadata":{"trusted":true,"_uuid":"74f3e99ddf43ed436392f9cb850823e574027f5c"},"cell_type":"code","source":"train_size <- round(file.info(\"../input/new-york-city-taxi-fare-prediction/train.csv\", extra_cols = TRUE)$size / 1000000000, 5)\nprint(paste(\"Training Data Size: \", train_size, \"gb\", sep = \"\"))\ntest_size <- round(file.info(\"../input/new-york-city-taxi-fare-prediction/test.csv\", extra_cols = TRUE)$size / 1000000000, 5)\nprint(paste(\"Test Data Size: \", test_size, \"gb\", sep = \"\"))\ndot_size <- round(file.info(\"../input/dot-file/DOT_Traffic_Speeds_NBE.csv\", extra_cols = TRUE)$size / 1000000000, 5)\nprint(paste(\"NYC DOT Data Size: \", dot_size, \"gb\", sep = \"\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"483e986b5f5b672f650e0e43293d2ac14bd2c335"},"cell_type":"markdown","source":"**STEP 4** : Import Base Data"},{"metadata":{"trusted":true,"_uuid":"50f1b4348dc7a468e9a13ba7f376aeb2e1b96631"},"cell_type":"code","source":"train_dirt <- read.csv(\"../input/new-york-city-taxi-fare-prediction/train.csv\",\n                        header = TRUE,\n                        colClasses = c(\n                            \"key\"=\"character\",\n                            \"fare_amount\"=\"numeric\",\n                            \"pickup_datetime\"=\"POSIXct\", ## in UTC\n                            \"dropoff_longitude\"=\"numeric\",\n                            \"pickup_longitude\"=\"numeric\",\n                            \"dropoff_latitude\"=\"numeric\",\n                            \"pickup_latitude\"=\"numeric\",\n                            \"passenger_count\"=\"integer\"\n                        ), nrows = train_rows_import) #%>% select(-key) # Preparations A through G were complete failures\n\ntrain_dirt <- dplyr::sample_n(train_dirt, train_rows_sample) # https://www.kaggle.com/docxian/nyc-taxi-get-subsample-of-data\ntrain_raw <- train_dirt\n\ntest_dirt <- read.csv(\"../input/new-york-city-taxi-fare-prediction/test.csv\",\n                        header = TRUE,\n                        colClasses = c(\n                            \"key\"=\"character\",\n                            \"pickup_datetime\"=\"POSIXct\",    ## in UTC\n                            \"dropoff_longitude\"=\"numeric\",\n                            \"pickup_longitude\"=\"numeric\",\n                            \"dropoff_latitude\"=\"numeric\",\n                            \"pickup_latitude\"=\"numeric\",\n                            \"passenger_count\"=\"integer\"\n                        )\n                    ) #%>% select(-key)\n\nprint(names(train_dirt))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f7a92db2952a41e890d57f3253e6ba8c1616d12"},"cell_type":"markdown","source":"**STEP 5** : Define Geographic Scope"},{"metadata":{"trusted":true,"_uuid":"2abc755318d6668b65a6ba01e52bad618c7ddd39"},"cell_type":"code","source":"# There's so much data it can't be worth it to keep NAs\ndirt_data_train <- na.omit(train_dirt)\ndirt_data_test <- na.omit(test_dirt) # * for now\n\n# Remove the lat/lon from the training data that are outside of what's present in the test data\ntrain_dirt <- train_dirt[train_dirt$pickup_latitude < max(test_dirt$pickup_latitude), ]\ntrain_dirt <- train_dirt[train_dirt$pickup_latitude > min(test_dirt$pickup_latitude), ]\ntrain_dirt <- train_dirt[train_dirt$dropoff_latitude < max(test_dirt$dropoff_latitude), ]\ntrain_dirt <- train_dirt[train_dirt$dropoff_latitude > min(test_dirt$dropoff_latitude), ]\ntrain_dirt <- train_dirt[train_dirt$pickup_longitude > min(test_dirt$pickup_longitude), ]\ntrain_dirt <- train_dirt[train_dirt$pickup_longitude < max(test_dirt$pickup_longitude), ]\ntrain_dirt <- train_dirt[train_dirt$dropoff_longitude > min(test_dirt$dropoff_longitude), ]\ntrain_dirt <- train_dirt[train_dirt$dropoff_longitude < max(test_dirt$dropoff_longitude), ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a56b9f775e7375c5dd2fe58fe0a74ee5adbcb2c"},"cell_type":"markdown","source":"** STEP 6 ** : Handle Outliers"},{"metadata":{"trusted":true,"_uuid":"13a91c78cac984ed3ea939811e87bedfd3940dbf"},"cell_type":"code","source":"# $2.50 starting rate & reasonable limit\ndirt_data_train <- dirt_data_train[dirt_data_train$fare_amount >= 2.50, ]  # Minimum $2.50 fare\ndirt_data_train <- dirt_data_train[dirt_data_train$fare_amount <= 300, ]  # Cap at $300 fare\n\n# dirt_data_train <- dirt_data_train[dirt_data_train$fare_amount >= 0, ]  # Minimum $0 fare\n\n# https://www.youtube.com/watch?v=R-yQw2UD50U\ndirt_data_train <- dirt_data_train[dirt_data_train$passenger_count <= 10, ]\ndirt_data_test <- dirt_data_test[dirt_data_test$passenger_count <= 10, ]\n\n# More than one passenger?\ndirt_data_train <- dirt_data_train[dirt_data_train$passenger_count >= 1, ] \ndirt_data_test <- dirt_data_test[dirt_data_test$passenger_count >= 1, ]\n# dirt_data_train <- dirt_data_train[dirt_data_train$passenger_count >= 0, ] \n# dirt_data_test <- dirt_data_test[dirt_data_test$passenger_count >= 0, ]\n\ntrain_dirt <- na.omit(train_dirt)\n\n# I used this combo to play with the variables and determine the realistic boundaries above\npar(mfrow=c(3,2))\nplot(density(train_dirt$fare_amount), main = \"fare_amount density\") # plots the results\nplot(density(train_dirt$passenger_count), main = \"passenger_count density\")\n\nplot(density(train_dirt$pickup_latitude), main = \"pickup latitude density\")\nplot(density(train_dirt$pickup_longitude), main = \"pickup longitude density\")\n\nplot(density(train_dirt$dropoff_latitude), main = \"dropoff latitude density\")\nplot(density(train_dirt$dropoff_longitude), main = \"dropoff longitude density\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49c4a38ef663d9c62107181fcf3614994012944a"},"cell_type":"code","source":"dirt_data_train <- train_dirt\ndirt_data_test <- test_dirt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9f06c8a75516049da8e91c1d716bcb9b2dd338f"},"cell_type":"markdown","source":"**STEP 7** : Latitudal & longitudal differences"},{"metadata":{"trusted":true,"_uuid":"9ae626b9869c1aa2097e7cb3048ee908e518f019"},"cell_type":"code","source":"# BASE DATA: Var 1 : Latitudal Differences \nlatdiff_1 <- abs(dirt_data_train$pickup_latitude) - abs(dirt_data_train$dropoff_latitude)\ndirt_data_train$latdiff_1 <- latdiff_1\nlatdiff_1 <- abs(dirt_data_test$pickup_latitude) - abs(dirt_data_test$dropoff_latitude)\ndirt_data_test$latdiff_1 <- latdiff_1\n# BASE DATA: Var 2 : Latittudal Differences \nlatdiff_2 <- abs(dirt_data_train$pickup_latitude - dirt_data_train$dropoff_latitude)\ndirt_data_train$latdiff_2 <- latdiff_2\nlatdiff_2 <- abs(dirt_data_test$pickup_latitude - dirt_data_test$dropoff_latitude)\ndirt_data_test$latdiff_2 <- latdiff_2\n# BASE DATA: Var 3 : Longitudal Differences \nlongdiff_1 <- abs(dirt_data_train$pickup_longitude) - abs(dirt_data_train$dropoff_longitude)\ndirt_data_train$longdiff_1 <- longdiff_1\nlongdiff_1 <- abs(dirt_data_test$pickup_longitude) - abs(dirt_data_test$dropoff_longitude)\ndirt_data_test$longdiff_1 <- longdiff_1\n# BASE DATA: Var 3 : Longitudal Differences \nlongdiff_2 <- abs(dirt_data_train$pickup_longitude - dirt_data_train$dropoff_longitude)\ndirt_data_train$longdiff_2 <- longdiff_2\nlongdiff_2 <- abs(dirt_data_test$pickup_longitude - dirt_data_test$dropoff_longitude)\ndirt_data_test$longdiff_2 <- longdiff_2\n\nprint(names(dirt_data_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5642337d1f53feb4749266ee39b29780a189756"},"cell_type":"markdown","source":"**STEP 8** : Distance & Bearing"},{"metadata":{"trusted":true,"_uuid":"24ec1d34024482e3e8872bf851104d47e1f4239e"},"cell_type":"code","source":"dirt_data_train <- dirt_data_train %>% rowwise() %>% \n                    mutate(crowdist = distHaversine(cbind(pickup_longitude, pickup_latitude), \n                                                    cbind(dropoff_longitude, dropoff_latitude)))\n\ndirt_data_test <- dirt_data_test %>% rowwise() %>% \n    mutate(crowdist = distHaversine(cbind(pickup_longitude, pickup_latitude), \n                                    cbind(dropoff_longitude, dropoff_latitude)))\n\nd_lat1 <- dirt_data_train$pickup_latitude\nd_lat2 <- dirt_data_train$dropoff_latitude\nd_lon1 <- dirt_data_train$pickup_longitude\nd_lon2 <- dirt_data_train$dropoff_longitude\n\nt_lat1 <- dirt_data_test$pickup_latitude\nt_lat2 <- dirt_data_test$dropoff_latitude\nt_lon1 <- dirt_data_test$pickup_longitude\nt_lon2 <- dirt_data_test$dropoff_longitude\n\nd_bearing <- atan2(cos(d_lat1)*sin(d_lat2)-sin(d_lat1)*cos(d_lat2)*cos(d_lon2-d_lon1), \n               sin(d_lon2-d_lon1)*cos(d_lat2)) \n\nt_bearing <- atan2(cos(t_lat1)*sin(t_lat2)-sin(t_lat1)*cos(t_lat2)*cos(t_lon2-t_lon1), \n               sin(t_lon2-t_lon1)*cos(t_lat2)) \n\ndirt_data_train$bearing <- d_bearing\ndirt_data_test$bearing <- t_bearing\n\nprint(names(dirt_data_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6c1f77f6646161ef7cddf9518e853ad4eeead79"},"cell_type":"markdown","source":"**STEP 9** : TODO : Airports & Landmarks"},{"metadata":{"trusted":true,"_uuid":"42b96f52fad99e04f6752d963bd9cd6f1220c19f"},"cell_type":"code","source":"# jfk_coords = (40.639722, -73.778889)\n# ewr_coords = (40.6925, -74.168611)\n# lga_coords = (40.77725, -73.872611)\n\n# middle_coords = (40.7141667,-74.0063889)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2787e1f8a565cfd4248291002e7c6cc4b1c24a4"},"cell_type":"markdown","source":"**STEP 10** : The Trip Strings"},{"metadata":{"trusted":true,"_uuid":"1eaefa95c794b1c5ca1b04c06e52efc55dffca1f"},"cell_type":"code","source":"dirt_data_train <- dirt_data_train %>% \nmutate(\"tripStr_3\" = paste(format(round(pickup_latitude, digits = 3), nsmall = 3), \n                           format(round(pickup_longitude, digits = 3), nsmall = 3),\n                           format(round(dropoff_latitude, digits = 3), nsmall = 3),\n                           format(round(dropoff_longitude, digits = 3), nsmall = 3),\n                           sep = \"|\"))\n\ndirt_data_test <- dirt_data_test %>% \nmutate(\"tripStr_3\" = paste(format(round(pickup_latitude, digits = 3), nsmall = 3), \n                           format(round(pickup_longitude, digits = 3), nsmall = 3),\n                           format(round(dropoff_latitude, digits = 3), nsmall = 3),\n                           format(round(dropoff_longitude, digits = 3), nsmall = 3),\n                           sep = \"|\"))     \n\ndirt_data_train <- dirt_data_train %>% \nmutate(\"tripStr_2\" = paste(format(round(pickup_latitude, digits = 2), nsmall = 2), \n                           format(round(pickup_longitude, digits = 2), nsmall = 2),\n                           format(round(dropoff_latitude, digits = 2), nsmall = 2),\n                           format(round(dropoff_longitude, digits = 2), nsmall = 2),\n                           sep = \"|\"))\n\ndirt_data_test <- dirt_data_test %>% \nmutate(\"tripStr_2\" = paste(format(round(pickup_latitude, digits = 2), nsmall = 2), \n                           format(round(pickup_longitude, digits = 2), nsmall = 2),\n                           format(round(dropoff_latitude, digits = 2), nsmall = 2),\n                           format(round(dropoff_longitude, digits = 2), nsmall = 2),\n                           sep = \"|\"))  \n\ndirt_data_train <- dirt_data_train %>% \nmutate(\"tripStr_1\" = paste(format(round(pickup_latitude, digits = 1), nsmall = 1), \n                           format(round(pickup_longitude, digits = 1), nsmall = 1),\n                           format(round(dropoff_latitude, digits = 1), nsmall = 1),\n                           format(round(dropoff_longitude, digits = 1), nsmall = 1),\n                           sep = \"|\"))\n\ndirt_data_test <- dirt_data_test %>% \nmutate(\"tripStr_1\" = paste(format(round(pickup_latitude, digits = 1), nsmall = 1), \n                           format(round(pickup_longitude, digits = 1), nsmall = 1),\n                           format(round(dropoff_latitude, digits = 1), nsmall = 1),\n                           format(round(dropoff_longitude, digits = 1), nsmall = 1),\n                           sep = \"|\"))  \n\ndirt_data_train$tripStr_3 <- gsub(\" \", \"\", dirt_data_train$tripStr_3, fixed = TRUE)\ndirt_data_test$tripStr_3 <- gsub(\" \", \"\", dirt_data_test$tripStr_3, fixed = TRUE)\n\ndirt_data_train$tripStr_2 <- gsub(\" \", \"\", dirt_data_train$tripStr_2, fixed = TRUE)\ndirt_data_test$tripStr_2 <- gsub(\" \", \"\", dirt_data_test$tripStr_2, fixed = TRUE)\n\ndirt_data_train$tripStr_1 <- gsub(\" \", \"\", dirt_data_train$tripStr_1, fixed = TRUE)\ndirt_data_test$tripStr_1 <- gsub(\" \", \"\", dirt_data_test$tripStr_1, fixed = TRUE)\n\nprint(\"---v--- 1-digit tripStr ---v---\")\nprint(head(dirt_data_train$tripStr_1,1))\nprint(\"---v--- 2-digit tripStr ---v---\")\nprint(head(dirt_data_train$tripStr_2,1))\nprint(\"---v--- 3-digit tripStr ---v---\")\nprint(head(dirt_data_train$tripStr_3,1))\nprint(\" \")\n\nprint(names(dirt_data_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db0e97015ad8b5653373b31b5b83fbc3db0720d8"},"cell_type":"markdown","source":"**STEP 11** : *Tempus Fugit"},{"metadata":{"trusted":true,"_uuid":"b833b73c1d5600d24e29c147036cebde5a82e47f"},"cell_type":"code","source":"# DD, MM, YYYY \ndirt_data_train$day <- format(as.Date(dirt_data_train$pickup_datetime), \"%d\")\ndirt_data_train$month <- as.factor(format(as.Date(dirt_data_train$pickup_datetime), \"%m\"))\ndirt_data_train$year <- format(as.Date(dirt_data_train$pickup_datetime), \"%Y\")\n\n# YYYY-MM-DD String\ndirt_data_train$date <- paste(format(as.Date(dirt_data_train$pickup_datetime), \"%Y\"), \n                              format(as.Date(dirt_data_train$pickup_datetime), \"%m\"),\n                              format(as.Date(dirt_data_train$pickup_datetime), \"%d\"), sep = \"-\")\n\n# Hour & Time Of Day\ndirt_data_train$hour <- (as.numeric(dirt_data_train$pickup_datetime) %% (24*60*60) / 3600) \ndirt_data_train$tod = cut(dirt_data_train$hour, \n                          breaks = c(0, 4, 9, 15, 18, 24),\n                          labels = c(\"h_early\", \"h_commute_to\", \"h_bizhrs\", \"h_commute_from\", \"h_night\"), \n                          include.lowest=TRUE, right=FALSE)\n\n# Day of Week\ndirt_data_train$dow <- as.factor(lubridate::wday(as.Date(dirt_data_train$pickup_datetime)))\n\n# V-- same stuff for test data (I probably didn't need to do it this way)\ndirt_data_test$day <- format(as.Date(dirt_data_test$pickup_datetime), \"%d\")\ndirt_data_test$month <- as.factor(format(as.Date(dirt_data_test$pickup_datetime), \"%m\"))\ndirt_data_test$year <- format(as.Date(dirt_data_test$pickup_datetime), \"%Y\")\ndirt_data_test$hour <- (as.numeric(dirt_data_test$pickup_datetime) %% (24*60*60) / 3600)\n\ndirt_data_test$tod = cut(dirt_data_test$hour, \n                         breaks = c(0, 4, 9, 15, 18, 24),\n                         labels = c(\"h_early\", \"h_commute_to\", \"h_bizhrs\", \"h_commute_from\", \"h_night\"), \n                         include.lowest=TRUE, right=FALSE)\n\ndirt_data_test$dow <- as.factor(lubridate::wday(as.Date(dirt_data_test$pickup_datetime)))\ndirt_data_test$date <- paste(format(as.Date(dirt_data_test$pickup_datetime), \"%Y\"), \n                              format(as.Date(dirt_data_test$pickup_datetime), \"%m\"),\n                              format(as.Date(dirt_data_test$pickup_datetime), \"%d\"), sep = \"-\")                          \n\ntest_raw <- cbind(dirt_data_test) # save this for later","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b90f0fa0f220fc3ecff4d58953b00446da79a947"},"cell_type":"markdown","source":"**STEP 12** : Load & Extract a sample of the DOT data then make a Trip String from the first and last points in the polyline."},{"metadata":{"_uuid":"1b942e3ddc47634ee17d875b87b85e64ca7724f9"},"cell_type":"markdown","source":"![](https://i.imgur.com/3kBXoUT.png)"},{"metadata":{"trusted":true,"_uuid":"0935767a7136aadb9b6e2352ae86ccb4942a43c1"},"cell_type":"code","source":"dot_trips <- read.csv(\"../input/dot-file/DOT_Traffic_Speeds_NBE.csv\",\n                        header=TRUE,\n                        colClasses=c(\n                            \"ID\" = \"character\",\n                            \"SPEED\" = \"numeric\", # probably MPH?\n                            \"TRAVEL_TIME\" = \"integer\", # probably minutes?\n                            \"STATUS\" = \"integer\", # DEPRICATED\n                            \"DATA_AS_OF\" = \"character\", # this is not useable, it's a floating timestamp\n                            \"LINK_POINTS\" = \"character\", #  \"40.683644,-73.72667001  40.68314,-73.72692  40.681365,-73.72806  40.678944,-73.72983  40.678236,-73.73047001\"\n                            \"BOROUGH\" = \"character\", # \"Queens\" \"Brooklyn\" \"Queens\" \"Queens\"\n                            \"ENCODED_POLY_LINE\" = \"character\",  # \"w_iwFtv~`MbBp@bJbFbN`JlC~BhJtJfFrEdHvFtDhCnW~OtAp@nE~CfB`BjBvBlCxGXlALrB}@xXCby@KpDyBva@\"\n                            \"ENCODED_POLY_LINE_LVLS\" = \"character\" # \"BBBBBBBBBBBBBBBBBBBBB\" \"BBBBB\" \"BBBBBBB\" \"BBBBBBB\"\n                            ), nrows = dot_rows_import) #%>% select(-ID)  # 15,651,405 total rows\n\n# TODO : Add nchar of ENCODED_POLY_LINE_LVLS ? easy, worth a try\n# TODO : Use the whole link_points string to generate full routes that can be subset\n\ndot_trips <- dplyr::sample_n(dot_trips, dot_rows_sample)\n\ndirt_dot_trips <- as.data.frame(dot_trips)\n\nprint(\" --- START STRUCTURE --- \")\nprint(names(dirt_dot_trips))\n\ndot_keeps <- c(\"SPEED\",\t\"TRAVEL_TIME\", \"LINK_POINTS\", \"BOROUGH\", \"ENCODED_POLY_LINE\", \"ENCODED_POLY_LINE_LVLS\")\ndirt_dot_trips <- as.data.frame(dirt_dot_trips[dot_keeps])\n\ndirt_dot_trips$SPEED <- as.numeric(dirt_dot_trips$SPEED)\ndirt_dot_trips$TRAVEL_TIME <- as.numeric(dirt_dot_trips$TRAVEL_TIME)\n\n# New York City Center Coords\nny_lat <- 40.785091\nny_lon <- -73.968285\n\ndirt_dot_trips$tripStr_1 <- 0\ndirt_dot_trips$tripStr_2 <- 0\ndirt_dot_trips$tripStr_3 <- 0\n\ndirt_dot_trips$str_lat <- word(dirt_dot_trips$LINK_POINTS,1)\ndirt_dot_trips$str_lon <- word(dirt_dot_trips$LINK_POINTS,1)\ndirt_dot_trips$end_lat <- word(dirt_dot_trips$LINK_POINTS,-1)\ndirt_dot_trips$end_lon <- word(dirt_dot_trips$LINK_POINTS,-1)\n\ndirt_dot_trips$str_lat <- strsplit(dirt_dot_trips$str_lat, \",\")\ndirt_dot_trips$str_lon <- strsplit(dirt_dot_trips$str_lon, \",\")\ndirt_dot_trips$end_lat <- strsplit(dirt_dot_trips$end_lat, \",\")\ndirt_dot_trips$end_lon <- strsplit(dirt_dot_trips$end_lon, \",\")\n\ndirt_dot_trips$str_lat <- word(dirt_dot_trips$str_lat,1)\ndirt_dot_trips$str_lon <- word(dirt_dot_trips$str_lon,2)\ndirt_dot_trips$end_lat <- word(dirt_dot_trips$end_lat,1)\ndirt_dot_trips$end_lon <- word(dirt_dot_trips$end_lon,2)\n\ndirt_dot_trips$str_lat <- as.numeric(str_extract(dirt_dot_trips$str_lat, \"\\\\-*\\\\d+\\\\.*\\\\d*\"))\ndirt_dot_trips$str_lon <- as.numeric(str_extract(dirt_dot_trips$str_lon, \"\\\\-*\\\\d+\\\\.*\\\\d*\"))\ndirt_dot_trips$end_lat <- as.numeric(str_extract(dirt_dot_trips$end_lat, \"\\\\-*\\\\d+\\\\.*\\\\d*\"))\ndirt_dot_trips$end_lon <- as.numeric(str_extract(dirt_dot_trips$end_lon, \"\\\\-*\\\\d+\\\\.*\\\\d*\"))\n\nlat1 <- as.numeric(dirt_dot_trips$str_lat)\nlat2 <- as.numeric(dirt_dot_trips$end_lat)\nlon1 <- as.numeric(dirt_dot_trips$str_lon)\nlon2 <- as.numeric(dirt_dot_trips$end_lon)\n\ndirt_dot_trips$lat1 <- lat1\ndirt_dot_trips$lon1 <- lon1\ndirt_dot_trips$lat2 <- lat2\ndirt_dot_trips$lon2 <- lon2\n                             \n# Distance & Bearing\ndirt_dot_trips <- dirt_dot_trips %>% rowwise() %>% \n                    mutate(crowdist = distHaversine(cbind(lon1, lat1), \n                                                    cbind(lon2, lat2)),\n                          bearing = atan2(cos(lat1)*sin(lat2)-sin(lat1)*cos(lat2)*cos(lon2-lon1), \n                               sin(lon2-lon1)*cos(lat2)))\n\n# Trip Strings\ndirt_dot_trips$str_lat <- format(round(dirt_dot_trips$str_lat, digits = 3), nsmall = 3)\ndirt_dot_trips$str_lon <- format(round(dirt_dot_trips$str_lon, digits = 3), nsmall = 3)\ndirt_dot_trips$end_lat <- format(round(dirt_dot_trips$end_lat, digits = 3), nsmall = 3)\ndirt_dot_trips$end_lon <- format(round(dirt_dot_trips$end_lon, digits = 3), nsmall = 3)\n\ndirt_dot_trips$tripStr_3 <- paste(dirt_dot_trips$str_lat, \n                                  dirt_dot_trips$str_lon,\n                                  dirt_dot_trips$end_lat,\n                                  dirt_dot_trips$end_lon,\n                                  sep = \"|\")\n\ndirt_dot_trips$str_lat <- format(round(as.numeric(dirt_dot_trips$str_lat), digits = 2), nsmall = 2)\ndirt_dot_trips$str_lon <- format(round(as.numeric(dirt_dot_trips$str_lon), digits = 2), nsmall = 2)\ndirt_dot_trips$end_lat <- format(round(as.numeric(dirt_dot_trips$end_lat), digits = 2), nsmall = 2)\ndirt_dot_trips$end_lon <- format(round(as.numeric(dirt_dot_trips$end_lon), digits = 2), nsmall = 2)\n\ndirt_dot_trips$tripStr_2 <- paste(dirt_dot_trips$str_lat, \n                                  dirt_dot_trips$str_lon,\n                                  dirt_dot_trips$end_lat,\n                                  dirt_dot_trips$end_lon,\n                                  sep = \"|\")\n\ndirt_dot_trips$str_lat <- format(round(as.numeric(dirt_dot_trips$str_lat), digits = 1), nsmall = 1)\ndirt_dot_trips$str_lon <- format(round(as.numeric(dirt_dot_trips$str_lon), digits = 1), nsmall = 1)\ndirt_dot_trips$end_lat <- format(round(as.numeric(dirt_dot_trips$end_lat), digits = 1), nsmall = 1)\ndirt_dot_trips$end_lon <- format(round(as.numeric(dirt_dot_trips$end_lon), digits = 1), nsmall = 1)\n\ndirt_dot_trips$tripStr_1 <- paste(dirt_dot_trips$str_lat, \n                                  dirt_dot_trips$str_lon,\n                                  dirt_dot_trips$end_lat,\n                                  dirt_dot_trips$end_lon,\n                                  sep = \"|\")\n\ndirt_dot_trips <- na.omit(dirt_dot_trips)  # when should I do this?\n#print(nrow(dirt_dot_trips))\n\n## Now break the data into three \ndirt_dot_trips_3 <- dirt_dot_trips\ndirt_dot_trips_2 <- dirt_dot_trips\ndirt_dot_trips_1 <- dirt_dot_trips\n\n## Remove all whitespace\ndirt_dot_trips_3$tripStr_3 <- gsub(\" \", \"\", dirt_dot_trips$tripStr_3, fixed = TRUE)\ndirt_dot_trips_2$tripStr_2 <- gsub(\" \", \"\", dirt_dot_trips$tripStr_2, fixed = TRUE) \ndirt_dot_trips_1$tripStr_1 <- gsub(\" \", \"\", dirt_dot_trips$tripStr_1, fixed = TRUE)\n\n## THIS MAKES SURE THE TRIP-STRINGS THE RIGHT LENGTH\ndirt_dot_trips_1 <- dirt_dot_trips_1[nchar(as.character(dirt_dot_trips_1$tripStr_1)) == 21, ]\ndirt_dot_trips_2 <- dirt_dot_trips_2[nchar(as.character(dirt_dot_trips_2$tripStr_2)) == 25, ] \ndirt_dot_trips_3 <- dirt_dot_trips_3[nchar(as.character(dirt_dot_trips_3$tripStr_3)) == 29, ]\n\ndirt_dot_trips_1 <- dirt_dot_trips_1[, c(\"tripStr_1\", \"SPEED\", \"TRAVEL_TIME\", \"bearing\", \"crowdist\") ]\ndirt_dot_trips_2 <- dirt_dot_trips_2[, c(\"tripStr_2\", \"SPEED\", \"TRAVEL_TIME\", \"bearing\", \"crowdist\") ] \ndirt_dot_trips_3 <- dirt_dot_trips_3[, c(\"tripStr_3\", \"SPEED\", \"TRAVEL_TIME\", \"bearing\", \"crowdist\") ]\n\ndirt_dot_trips <- na.omit(dirt_dot_trips) \n\nprint(\" --- END STRUCTURE --- \")\nprint(names(dirt_dot_trips))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62073046c830e63dca4863e7b0c851bbe9565941"},"cell_type":"markdown","source":"**STEP 13** : Scatter Maps (WORKING ON REMOVING WATER POINTS)"},{"metadata":{"trusted":true,"_uuid":"d383f80af7ba85f764bdf07724abcedf4dfdc814","scrolled":false},"cell_type":"code","source":"# https://www.kaggle.com/nulldata/nyc-map-just-with-taxi-pickup-and-drop-locations\n# options(repr.plot.width = 12, repr.plot.height = 10)\nlibrary(grid)\n#reference: https://gist.github.com/jslefche/eff85ef06b4705e6efbc\nlibrary(gridExtra)\n\n# print(paste(\"Waterworld Rows : \", nrow(dirt_data_train)))\n\nmin_lat <- min(test_dirt$pickup_latitude, test_dirt$dropoff_latitude)\nmax_lat <- max(test_dirt$pickup_latitude, test_dirt$dropoff_latitude)\nmin_lon <- min(test_dirt$pickup_longitude, test_dirt$dropoff_longitude)\nmax_lon <- max(test_dirt$pickup_longitude, test_dirt$pickup_longitude)\n\n# (-74.5, -72.8, 40.5, 41.8)\nbox_0 <- c(min_lon, max_lon, min_lat, max_lat) # TEST SCOPE\nbox_1 <- c(-74.5, -72.8, 40.5, 41.8)           # 1242x1262\nbox_2 <- c(-74.3, -73.7, 40.5, 40.9) # 1752 wide x 1538 high - CLOSE UP\nbox_3 <- c(-74, -73.95, 40.7, 40.8)  # EXTREME CLOSE UP!\n\nboundary <- box_1\n\nmap_1 <- na.omit(dirt_data_train)\nmap_2 <- na.omit(dirt_data_test)\nmap_3 <- dirt_dot_trips\n\n# print(str(map_1))\n# print(head(map_3$lon1))\n\nimg_1 <- png::readPNG(\"../input/carta10/carta10.png\") \nimg_1_inv <- png::readPNG(\"../input/carta10inv/carta10inv.png\") \nimg_1_blk <- png::readPNG(\"../input/carta12blk/carta10blk.png\") #[:,:,0] > 0.9\n\nimg_2 <- png::readPNG(\"../input/carta11/carta11.png\") \nimg_2_inv <- png::readPNG(\"../input/carta11inv/carta11inv.png\") \nimg_2_blk <- png::readPNG(\"../input/carta11blk/carta11blk.png\") \n\nlibrary(biOps)\nimg_2_jpg <- biOps::readJpeg(\"../input/carta11blkjpg/carta11blkjpeg.jpeg\")\nimg_2_mat <- biOps::imagedata(img_2_jpg, type = \"grey\")\n\nblack_map <- as.matrix(img_2_mat)\n\n# print(dim(black_map))\n\nplot(black_map, main = \"BLACK LAND - WHITE WATER MAP\")\n\ndx <- dim(black_map)[1]\ndy <- dim(black_map)[2]\n\nmap_1 <- map_1 %>% rowwise() %>% \n                    mutate(xpx = as.integer(dx * (map_1$pickup_longitude - boundary[1]) / (boundary[2]-boundary[1])), \n                           ypx = as.integer(dy - dy * (map_1$pickup_latitude - boundary[3]) / (boundary[4]-boundary[3])))\n\n# map_1$in_water <- black_map[map_1$xpx, map_1$ypx]\n# idx <- black_map[head(map_1$xpx, 20), head(map_1$ypx,20)]\n# map_1_a <- head(map_1, 200)\n# black_map[map_1$xpx, map_1$ypx]\n# pickup_xpx <- as.vector(map_1$xpx)\n# pickup_ypx <- as.vector(map_1$ypx)\n\n# library(bigmemory)\n\n# black_map <- big.matrix(as.big.matrix(black_map), type = \"integer\", shared = TRUE, ncol = dx, nrow = dy)\n\n# in_water <- function(x,y) {\n#     return(black_map[x,y] > 200)\n# }\n\n# map_1$in_water <- in_water(pickup_xpx, pickup_ypx)\n\n\n# print(str(map_1_a))\n# 255 is white\n#  lon lon wid . -- lat lat hei\n# (-74.5, -72.8,  -- 40.5, 41.8) \n# box_1  = 1752 wide x 1538 height\n# point =  40.75719, -73.99724\n# .      as.integer(dy - dy * (lat - bound[2]) / (bound[3]-bound[2])) \n# lon -> 1752 * ((-73.99724)-(-74.5)) / ((-72.8)-(-74.5))\n#       as.integer(dx * (lon - bound[0]) / (bound[1]-bound[0]))\n# lat -> 1538 - (1538 * (40.75719 - 40.5) / (41.8 - 40.5))\n# lat_y <- function(lat, dy, bound) {\n#     res <- as.integer(dy - dy * (lat - bound[2]) / (bound[3]-bound[2]))   \n# }\n# lon_x <- function(lon, dx, bound) {\n#     res <- as.integer(dx*(lon - bound[0])/(bound[1]-bound[0]))\n# }\n# result <- apply(head(map_1, 20), 1, isWater(map_1$pickup_longitude, map_1$pickup_latitude, \n#                         dim(black_map)[1], dim(black_map)[2], \n#                         boundary))\n# isWater <- function(lon, lat, xpx, ypx, boundary) {\n#  #   c(-74.5, -72.8, 40.5, 41.8)\n# #     print(paste(lon, lat))\n# #     print(paste(xpx, ypx))\n# #     print(boundary)\n# #     print(img_2_mat[100,100])\n#     return(1234)\n# }\n# print(head(result, 20))\n     \n# lat_y <- function(lat, dy, bound) {\n#     res <- as.integer(dy - dy * (lat - bound[2]) / (bound[3]-bound[2]))\n#     return(res)\n# }\n# lon_x <- function(lon, dx, bound) {\n#     res <- as.integer(dx*(lon - bound[0])/(bound[1]-bound[0]))\n#     return(res)\n# }\n\ng_1 <- rasterGrob(img_1, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE)\ng_1_inv <- rasterGrob(img_1_inv, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE) \ng_1_blk <- rasterGrob(img_1_blk, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE) \n\ng_2 <- rasterGrob(img_2, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE) \ng_2_inv <- rasterGrob(img_2_inv, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE) \ng_2_blk <- rasterGrob(img_2_blk, width=unit(1,\"npc\"), height=unit(1,\"npc\"), interpolate = FALSE) \n\n# TRAIN Inverted & ZOOMED\nggplot(map_1, aes(x = pickup_longitude, y = pickup_latitude), margin = FALSE ) +\n               annotation_custom(g_2_inv, xmin=box_2[1], xmax=box_2[2], ymin=box_2[3], ymax=box_2[4]) +\n               geom_point(color = \"red\", size = 0.01, alpha = 1/2) +\n               geom_point(color = \"blue\", data = map_1, aes(x = dropoff_longitude, y = dropoff_latitude), size = 0.01, alpha = 1/10) +\n               geom_point(color = \"orange\", data = map_3, aes(x = lon1, y = lat1), size = 0.5, alpha = 1/2) +\n               scale_x_continuous(limits = c(box_2[1], box_2[2])) +\n               scale_y_continuous(limits = c(box_2[3], box_2[4])) +\n               ggtitle(\"Red Pickups, Blue Dropoffs, Orange Speed Measurement Points\")\n\n# grid.arrange(cart_1, cart_2, cart_3, cart_4, cart_5, cart_6, ncol = 2)\n\n# print(paste(\"Landworld Rows : \", nrow(dirt_data_train)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fe6d1a28aceb8b05ac2db307117db4caa9c82ff"},"cell_type":"markdown","source":"https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration?scriptVersionId=5341553\n\n^ I have some significant progress in this above but I'm hitting memory limits."},{"metadata":{"_uuid":"2e768b91469cf992525a5450e4604f0041fabebd"},"cell_type":"markdown","source":"**STEP 14** : Compare Trip String columns in the two datasets"},{"metadata":{"trusted":true,"_uuid":"b1ba8dc337577741805cb1a145054ace55a0a62f"},"cell_type":"code","source":"dot_count_1 <- dirt_dot_trips_1 %>% group_by(tripStr_1) %>% dplyr::summarize(count=n())\ndot_count_2 <- dirt_dot_trips_2 %>% group_by(tripStr_2) %>% dplyr::summarize(count=n())\ndot_count_3 <- dirt_dot_trips_3 %>% group_by(tripStr_3) %>% dplyr::summarize(count=n())\n\ntrain_count_1 <- dirt_data_train %>% group_by(tripStr_1) %>% dplyr::summarize(count=n())\ntrain_count_2 <- dirt_data_train %>% group_by(tripStr_2) %>% dplyr::summarize(count=n())\ntrain_count_3 <- dirt_data_train %>% group_by(tripStr_3) %>% dplyr::summarize(count=n())\n\ndot_results <- data.frame(\"tripStr\" = c(1:3), \n                          \"avg_sample_size\" = c(mean(dot_count_1$count), \n                                                mean(dot_count_2$count),\n                                                mean(dot_count_3$count)),\n                          \"unique count\" = c(nrow(dot_count_1), \n                                             nrow(dot_count_2),\n                                             nrow(dot_count_3))\n                      )\n\ntrain_results <- data.frame(\"tripStr\" = c(1:3), \n                          \"avg_sample_size\" = c(mean(train_count_1$count), \n                                                mean(train_count_2$count),\n                                                mean(train_count_3$count)),\n                          \"unique count\" = c(nrow(train_count_1), \n                                             nrow(train_count_2),\n                                             nrow(train_count_3))\n                      )\n\nprint(\"------- DEPARTMENT OF TRANSPORTATION ------\")\nprint(dot_results)\nprint(\"------------- TAXI DATA -------------------\")\nprint(train_results)\n# print(\"------------- DATE RANGE ------------------\")\n# print(paste(\"TEST date range : \", min(dirt_data_test$year) , \"-\", max(dirt_data_test$year)))\n# print(paste(\"TRAIN date range : \", min(dirt_data_train$year) , \"-\", max(dirt_data_train$year)))\n    \ndirt_dot_trips <- na.omit(as.data.frame(dirt_dot_trips))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f68d019cb88c99119af9f1ca130496b4975867f"},"cell_type":"markdown","source":"**STEP 15** : Now aggregeate the DOT dataset so we have average speed and travel_time for each Trip String at each level of resolution."},{"metadata":{"trusted":true,"_uuid":"3b1749f91ba8d1c6351ee0a622565a567dd1e584","_kg_hide-output":false,"scrolled":false},"cell_type":"code","source":"dot_keeps <- c(\"tripStr_1\", \"tripStr_2\", \"tripStr_3\", \"SPEED\", \"TRAVEL_TIME\", \"bearing\", \"crowdist\") \n\ntS_1_keeps <- c(\"tripStr_1\", \"SPEED\", \"TRAVEL_TIME\")\ntS_2_keeps <- c(\"tripStr_2\", \"SPEED\", \"TRAVEL_TIME\")\ntS_3_keeps <- c(\"tripStr_3\", \"SPEED\", \"TRAVEL_TIME\")\n\ndirt_dot_trips <- dirt_dot_trips[dot_keeps]\n\ndirt_dot_trips_3 <- dirt_dot_trips_3[!grepl(\"NA\", dirt_dot_trips_3$tripStr_3),]\ndirt_dot_trips_2 <- dirt_dot_trips_2[!grepl(\"NA\", dirt_dot_trips_2$tripStr_2),]\ndirt_dot_trips_1 <- dirt_dot_trips_1[!grepl(\"NA\", dirt_dot_trips_1$tripStr_1),]\n\ndirt_dot_trips_3 <- dirt_dot_trips_3[tS_3_keeps]\ndirt_dot_trips_2 <- dirt_dot_trips_2[tS_2_keeps]\ndirt_dot_trips_1 <- dirt_dot_trips_1[tS_1_keeps]\n\nagg_dot_clean_3 <- dirt_dot_trips_3 %>%\n  group_by(tripStr_3) %>%\n  summarise_all(funs(mean(., na.rm = TRUE)))\n\nagg_dot_clean_2 <- dirt_dot_trips_2 %>%\n  group_by(tripStr_2) %>%\n  summarise_all(funs(mean(., na.rm = TRUE)))\n\nagg_dot_clean_1 <- dirt_dot_trips_1 %>%\n  group_by(tripStr_1) %>%\n  summarise_all(funs(mean(., na.rm = TRUE)))\n\nagg_dot_clean_1 <- agg_dot_clean_1[tS_1_keeps]\nagg_dot_clean_2 <- agg_dot_clean_2[tS_2_keeps]\nagg_dot_clean_3 <- agg_dot_clean_3[tS_3_keeps]\n\n# print(colSums(is.na(agg_dot_clean_1)))\n# print(head(agg_dot_clean_1))\nprint(str(agg_dot_clean_1))\n\npsych::describe(agg_dot_clean_1)\npsych::describe(agg_dot_clean_2)\npsych::describe(agg_dot_clean_3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afec23cc7a9f69ef5ab114306c015c4a94179067"},"cell_type":"markdown","source":"**STEP 16** : Now fill new columns in the test & train dataset with their associated average speed and travel_time. (starting with .000, .00, .0)"},{"metadata":{"trusted":true,"_uuid":"218e8d077a8f9f5a579180d7e534fad4962834e5"},"cell_type":"code","source":"## Add Columns to Training Data : tripStr_3\ndirt_data_train <- cbind(agg_dot_clean_3[match(dirt_data_train$tripStr_3, agg_dot_clean_3$tripStr_3),2], dirt_data_train)\ndirt_data_train <- cbind(agg_dot_clean_3[match(dirt_data_train$tripStr_3, agg_dot_clean_3$tripStr_3),3], dirt_data_train)\n##                                tripStr_2\ndirt_data_train <- cbind(agg_dot_clean_2[match(dirt_data_train$tripStr_2, agg_dot_clean_2$tripStr_2),2], dirt_data_train)\ndirt_data_train <- cbind(agg_dot_clean_2[match(dirt_data_train$tripStr_2, agg_dot_clean_2$tripStr_2),3], dirt_data_train)\n##                                tripStr_1\ndirt_data_train <- cbind(agg_dot_clean_1[match(dirt_data_train$tripStr_1, agg_dot_clean_1$tripStr_1),2], dirt_data_train)\ndirt_data_train <- cbind(agg_dot_clean_1[match(dirt_data_train$tripStr_1, agg_dot_clean_1$tripStr_1),3], dirt_data_train)\n\n## Add Columns to Test Data : tripStr_3\ndirt_data_test <- cbind(agg_dot_clean_3[match(dirt_data_test$tripStr_3, agg_dot_clean_3$tripStr_3),2], dirt_data_test)\ndirt_data_test <- cbind(agg_dot_clean_3[match(dirt_data_test$tripStr_3, agg_dot_clean_3$tripStr_3),3], dirt_data_test)\n##                            tripStr_2\ndirt_data_test <- cbind(agg_dot_clean_2[match(dirt_data_test$tripStr_2, agg_dot_clean_2$tripStr_2),2], dirt_data_test)\ndirt_data_test <- cbind(agg_dot_clean_2[match(dirt_data_test$tripStr_2, agg_dot_clean_2$tripStr_2),3], dirt_data_test)\n##                            tripStr_1\ndirt_data_test <- cbind(agg_dot_clean_1[match(dirt_data_test$tripStr_1, agg_dot_clean_1$tripStr_1),2], dirt_data_test)\ndirt_data_test <- cbind(agg_dot_clean_1[match(dirt_data_test$tripStr_1, agg_dot_clean_1$tripStr_1),3], dirt_data_test)\n\n# print(names(dirt_data_train))\n# print(head(dirt_data_train, 10))\n# print(str(dirt_data_train))\n# print(colSums(is.na(data_test)))\n\n# Create the tripStr Columns and fill train data with tripStr_3\ndirt_data_train$tripStr <- dirt_data_train$tripStr_3\nmy.na <- is.na(dirt_data_train$tripStr)\ndirt_data_train$tripStr[my.na] <- dirt_data_train$tripStr_3[my.na]\n#                                                    tripStr_2\ndirt_data_train$tripStr <- dirt_data_train$tripStr_2\nmy.na <- is.na(dirt_data_train$tripStr)\ndirt_data_train$tripStr[my.na] <- dirt_data_train$tripStr_2[my.na]\n#                                                    tripStr_1\ndirt_data_train$tripStr <- dirt_data_train$tripStr_1\nmy.na <- is.na(dirt_data_train$tripStr)\ndirt_data_train$tripStr[my.na] <- dirt_data_train$tripStr_1[my.na]\n\n# Create the tripStr Columns and fill test data with tripStr_3\ndirt_data_test$tripStr <- dirt_data_test$tripStr_3\nmy.na <- is.na(dirt_data_test$tripStr)\ndirt_data_test$tripStr[my.na] <- dirt_data_test$tripStr_3[my.na]\n#                                                    tripStr_2\ndirt_data_test$tripStr <- dirt_data_test$tripStr_2\nmy.na <- is.na(dirt_data_test$tripStr)\ndirt_data_test$tripStr[my.na] <- dirt_data_test$tripStr_2[my.na]\n#                                                    tripStr_1\ndirt_data_test$tripStr <- dirt_data_test$tripStr_1\nmy.na <- is.na(dirt_data_test$tripStr)\ndirt_data_test$tripStr[my.na] <- dirt_data_test$tripStr_1[my.na]\n\n\nremaining_train_na <- sum(is.na(dirt_data_train$tripStr))\nremaining_train_na <- sum(is.na(dirt_data_train$SPEED))\nremaining_test_na <- sum(is.na(dirt_data_test$tripStr))\nremaining_test_na <- sum(is.na(dirt_data_test$SPEED))\n\n# print(remaining_train_na)\n# print(remaining_test_na)\n# print(head(dirt_data_train))\n# print(str(dirt_data_train))\n# print(names(dirt_data_train))\n\nprint(paste(round((1 - sum(is.na(dirt_data_train$SPEED)) / train_rows_sample)*100, 2), \n            \"percent tripStr match rate in training data\") )\nprint(paste(round((1 - sum(is.na(dirt_data_test$SPEED)) / nrow(test_raw))*100, 2), \n            \"percent tripStr match rate in test data\") )\n\n# print(head(dirt_data_test))\n# print(str(dirt_data_test))\nprint(names(dirt_data_test))\nprint(colSums(is.na(dirt_data_test))) # note we have some duplicate columns...","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d088cc4fb3a018b2e61b83f5f15b87b858dc21a"},"cell_type":"markdown","source":"**STEP 17** : Setup base data for KNN imputation of DOT info for unmatched trip strings"},{"metadata":{"trusted":true,"_uuid":"36a14d96ace0a1dfe4861e2c85451589fd17482c","scrolled":true},"cell_type":"code","source":"d_keeps <- c(\"fare_amount\", \"longdiff_1\", \"latdiff_1\", \"longdiff_2\", \"latdiff_2\", \"crowdist\", \"TRAVEL_TIME\", \"SPEED\", \"bearing\")\nt_keeps <- c(\"key\", \"longdiff_1\", \"latdiff_1\", \"longdiff_2\", \"latdiff_2\", \"crowdist\", \"TRAVEL_TIME\", \"SPEED\", \"bearing\")\n\ndata_train <- na.omit(as.data.frame(dirt_data_train[d_keeps]))\n\n#print(names(data_test))\n#data_test <- as.data.frame(dirt_data_test)\ndata_test <- as.data.frame(dirt_data_test[t_keeps])\nprint(names(data_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c75d50fcc4935f546bf8e4207558217283e1a0e"},"cell_type":"markdown","source":"**STEP 18** : Impute the missing SPEED & TRAVEL_TIME variables into the test data"},{"metadata":{"trusted":true,"_uuid":"e2cb807b6a9f0cf417535f85147600359271b53f","scrolled":false},"cell_type":"code","source":"data_test_speed <- data_test\ndata_test_time <- data_test\n\ndata_test$SPEED <- NA\ndata_test$TRAVEL_TIME <- NA\n\nprint(\">>> PRE IMPUTATION <<<\")\nprint(\"-- str test speed --\")\nprint(str(data_test_speed))\nprint(colSums(is.na(data_test_speed)))\n\ndata_test_speed <- dplyr::select_if(data_test_speed, is.numeric) \ndata_test_time <- dplyr::select_if(data_test_time, is.numeric) \n\nprint(\"imputing...\")\nprint(names(data_test))\n\n# print(\"speed right before imputation\")\n# print(names(data_test_speed))\n# print(colSums(is.na(data_test_speed)))\n# print(colSums(data_test_speed))\n\n# print(head(data_test_speed))\n# print(head(data_test_speed$SPEED, 30))\n\ndata_test_speed <- DMwR::knnImputation(data_test_speed[, !names(data_test_speed) %in% \"SPEED\"], scale = TRUE )\n\ndata_test_time <- DMwR::knnImputation(data_test_time[, !names(data_test_time) %in% \"TRAVEL_TIME\"], scale = TRUE)\n\ndata_test <- cbind(data_test_speed, data_test)\ndata_test <- cbind(data_test_time, data_test)\n\nprint(\">>> IMPUTATION COMPLETE <<<\")\nprint(\"-- data-test --\")\n#print(str(data_test))\nprint(names(data_test))\n#print(colSums(is.na(data_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"398dc83c086292240f170167f8428f391da96569"},"cell_type":"markdown","source":"STEP ? : Make all clean data available"},{"metadata":{"trusted":true,"_uuid":"8d69e4095a6677b3003d2be74bd2ae7b71bd0385"},"cell_type":"code","source":"train_keeps <- c(\"fare_amount\", \n                  \"TRAVEL_TIME\", \n                  \"SPEED\", \n                  \"longdiff_1\",\n                 \"latdiff_1\", \n                 \"longdiff_2\", \"latdiff_2\",\n                 \"crowdist\", \"bearing\",\n                 \"month\", \"year\", \n                 \"dow\",\n                 \"tod\",\n                 \"hour\", \n                 \"passenger_count\"\n                )\n\ntest_keeps <- c(\"TRAVEL_TIME\",\n                \"SPEED\", \n                \"longdiff_1\", \n                \"latdiff_1\", \"longdiff_2\", \"latdiff_2\",\n                \"crowdist\", \"bearing\", \n                \"dow\",\n                \"tod\",\n                \"month\", \"year\",\n                \"hour\", \n                \"passenger_count\"\n                )\n\ndata_test <- cbind(test_raw, data_test)\ndata_test <- data_test[ , colSums(is.na(data_test)) == 0] ## this makes sure that there are no NA values in the test data\n\n## Go through each row and determine if a value is zero\n\nprint(nrow(dirt_data_train))\ndirt_data_train <- dirt_data_train[dirt_data_train$crowdist > 0, ]          \nprint(max(dirt_data_test$hour))\nprint(min(dirt_data_test$hour))\n                \nprint(\" *** END GOAL DATASETS *** \")\n# END GOAL : TRAIN DATA WITH MORE COLUMNS\n# *************************\ndata_train <- na.omit(as.data.frame(dirt_data_train[train_keeps]))\ndata_stack_train <- na.omit(as.data.frame(dirt_data_train[train_keeps]))\n# ************************\n# END GOAL : TEST DATA WITH MORE COLUMNS\n# ************************\ndata_test <- as.data.frame(data_test[test_keeps])\n# *************************\n\n# CHECK\n# print(colSums(is.na(data_test)))\n# print(nrow(is.na(data_test)))\nprint(str(data_test))\n# summary(data_test)\n\nprint(\"  ** TEST ** \")\nprint(names(data_test))\nprint(\" ** TRAIN ** \")\nprint(names(data_train))\n\npsych::describe(data_test)\npsych::describe(data_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72155554838dff482eda6731292b4a8dfa9b85e3"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"7b93fadabcee2e1f962bb5c3fe7edd7ed509d0f9"},"cell_type":"markdown","source":"**STEP X** : Principal Component Analysis"},{"metadata":{"trusted":true,"_uuid":"ede3182b0406905a991d052e911591bfb4167982"},"cell_type":"code","source":"# par(mfrow=c(3,1)) #2x2\n\nallNumeric <- dplyr::select_if(data_train, is.numeric) \n\n# print(names(allNumeric))\n\n# print(e1071::skewness(allNumeric$crowdist))\n# print(e1071::skewness(allNumeric$TRAVEL_TIME))\n# print(e1071::skewness(allNumeric$SPEED))\n# print(e1071::skewness(allNumeric$bearing))\n# print(e1071::skewness(allNumeric$hour))\n# print(e1071::skewness(allNumeric$passenger_count))\n\n\nfit <- princomp(allNumeric, cor = TRUE) # extracting PCs from the correlation matrix \n\n# summary(fit) # print variance accounted for \n# loadings(fit) # pc loadings \n# fit$scores # the principal components\n\n# Determine Number of Factors to Extract (looks like 2 or 3)\nev <- eigen(cor(allNumeric)) # get eigenvalues\nap <- parallel(subject = nrow(allNumeric), var = ncol(allNumeric),\n  rep = 100, cent = 0.05)\nnS <- nScree(x = ev$values, aparallel = ap$eigen$qevpea)\n\nplot(fit, type = \"lines\", main = \"scree plot\") # scree plot \nbiplot(fit, main = \"biplot\", cex = 0.6)\nplotnScree(nS)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ec88ae662dc263e6fd481fd69a1ef0127741c02"},"cell_type":"markdown","source":"**STEP 19** : Correlograms with relaxing significance levels"},{"metadata":{"trusted":true,"_uuid":"f53e0104e9900ebd34da005bc6b3647d3478de8c","scrolled":true},"cell_type":"code","source":"allNumeric <- dplyr::select_if(data_train, is.numeric) \ncorr <- cor(allNumeric, method = \"spearman\")\nmat <- allNumeric\n\n# # https://medium.swirrl.com/@northernjamie Thanks Jamie\ncor.mtest <- function(mat, conf.level = 0.95){\n    mat <- as.matrix(mat)\n    n <- ncol(mat)\n    p.mat <- lowCI.mat <- uppCI.mat <- matrix(NA, n, n)\n    diag(p.mat) <- 0\n    diag(lowCI.mat) <- diag(uppCI.mat) <- 1\nfor(i in 1:(n-1)){\n    for(j in (i+1):n){\n        tmp <- cor.test(mat[,i], mat[,j], conf.level = conf.level)\n        p.mat[i,j] <- p.mat[j,i] <- tmp$p.value\n        lowCI.mat[i,j] <- lowCI.mat[j,i] <- tmp$conf.int[1]\n        uppCI.mat[i,j] <- uppCI.mat[j,i] <- tmp$conf.int[2]\n    }\n}\nreturn(list(p.mat, lowCI.mat, uppCI.mat))\n}\nres1 <- cor.mtest(corr,0.95)\n\npar(mfrow=c(3,3))\n\nsig <- c(0.00100, 0.00230, 0.00529, 0.01217, 0.02798, 0.06436, 0.14804, 0.34048, 0.499999999)\n\nfor (i in 1:9){\n  corrplot(corr, method = \"square\", order = \"hclust\", tl.col = \"black\", \n                     tl.cex = 0.75, p.mat = res1[[1]], sig.level = sig[i],  \n                     insig = \"pch\", pch.cex = 1, main = paste(\"sig level \", sig[i]), \n                     bg = \"white\", addrect = 3)\n}\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c77281bc1d4f3bc86f26a3f596170c974ce779d"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"b876d46a1cbaee928cda3b51218c8c4065f72111"},"cell_type":"code","source":"round(corr,3)\npairs(fare_amount ~ ., data = corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44b3bf78d4f18e9d9bce56fa7f03c3edb168e779"},"cell_type":"code","source":"# this is where the data should be checked","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4a4bf5ccd639e675c06b62061be47f8eb8e16ea"},"cell_type":"markdown","source":"**STEP 20** : Caret modeling config"},{"metadata":{"trusted":true,"_uuid":"d222dadc41dd861e440da634574497d3872bb242"},"cell_type":"code","source":"labelName <- 'fare_amount'\npredictors <- names(data_train)[names(data_train) != labelName]\n\nprint(predictors)\n\nPP <- c('pca', 'nzv', 'medianImpute', 'center', 'scale')\n#PP <- c('medianImpute', 'center', 'scale')\n\ntrain_folds <- train_folds \ntrain_depth <- train_depth\ntrain_repeats <- train_repeats\n\nmyGrid <- expand.grid(alpha = 0:1, lambda = seq(0.0001, 0.02, length = train_tuneLength))\n\nmyControl <- trainControl(method = \"cv\", # cross validation of models (cv, boot, repeated_cv)\n                          number = train_folds,\n                          summaryFunction = defaultSummary,\n                          #summaryFunction = twoClassSummary,\n                          #classProbs = TRUE, # IMPORTANT!\n                          savePredictions = 'final',\n                          verboseIter = FALSE,\n                          allowParallel = TRUE\n                          #index = myFolds # For Stacks\n                          )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72c928765647390b232834973f88f9362d25810c"},"cell_type":"markdown","source":"**STEP 21** : Setup a df to use to collect results manually"},{"metadata":{"trusted":true,"_uuid":"c69f80a77ed553917b5e3d4eec2f2dc7ea18eaad","scrolled":true},"cell_type":"code","source":"model_list <- c(\"lm\", \"gbm\", \"xgBoost\", \"blackboost\")\nmodel_results <- as.data.frame(model_list)\nmodel_results$RMSE <- NA\nmodel_results$r2 <- NA\nmodel_results$MAE <- NA\n\nprint(model_results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b2ce259ed8f9f416e7cba54ca45bb849d32101a"},"cell_type":"markdown","source":"**MODEL 1 : STRAIGHT LINEAR MODEL**"},{"metadata":{"trusted":true,"_uuid":"2a78c2e56094716f6b5a44d4aa18aeb8a9d74dc8"},"cell_type":"code","source":"\n# \"TRAVEL_TIME\", \"longdiff_2\", \"latdiff_2\", \"crowdist\", \"bearing\",\n# \"month\", \"year\", \"dow\",\"tod\",\"hour\", \"passenger_count\"\n# crowdist + latdiff_2 + year + longdiff_2 + dow + tod\nlm_1 <- lm(\n    fare_amount ~ .\n#     longdiff_2 + crowdist\n#          +  log(TRAVEL_TIME)\n# #                            + bearing\n            \n#            + latdiff_2\n           \n# # #                            + month \n#                             + year \n#                             + dow \n#                             + tod                    \n# #         + passenger_count\n           , data_train)\n\nm_1 <- caret::train(fare_amount ~ .,\n                    data = data_train,\n                    method = \"lm\",\n                    preProcess = PP,\n                    trControl = myControl\n                    )\n\n# results <- c(\"lm\", summary(lm_1)$sigma, summary(lm_1)$r.squared, NA)\n# model_results <- rbind(model_results, results)\n\nprint(caret::varImp(m_1))\n# print(na.omit(model_results))\n# #attributes(summary(lm_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f51f7bca5d72837d92549b3e527d6ff96d93c893","scrolled":true},"cell_type":"code","source":"print(summary(m_1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55e7f2518a3aa1a6098290d5e2318b440c1be064"},"cell_type":"markdown","source":"**MODEL 2** : STOCHASTIC GRADIENT BOOSTING"},{"metadata":{"trusted":true,"_uuid":"a7e8c66023d0bbcc5b6522ab0b617f2c4f4227c0","_kg_hide-output":true,"_kg_hide-input":false,"scrolled":true},"cell_type":"code","source":"# m_2 <- caret::train(fare_amount ~ crowdist + TRAVEL_TIME + latdiff_2 + year + longdiff_2 + dow + tod,\nm_2 <- caret::train(fare_amount ~ .,\n    data = data_train,\n    method = \"gbm\",\n    metric = \"RMSE\",\n    preProcess = PP,\n    trControl = myControl,\n    tuneGrid = expand.grid(interaction.depth = train_depth,\n                            n.trees = train_trees,  \n                            shrinkage = 0.1,\n                            n.minobsinnode = 10)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2beb738f1c616b87a9842ca5960ec932ec364646","scrolled":false},"cell_type":"code","source":"print(caret::varImp(m_2))\nprint(m_2)\n# results <- c(\"gbm\", m_2$results$RMSE, m_2$results$Rsquared, m_2$results$MAE)\n# model_results <- rbind(model_results, results)\n# print(na.omit(model_results))\n# attributes(m_2)\n# print(m_2$results$RMSE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a95ed4fc438020a4141f9cff11cb9785f64672da"},"cell_type":"markdown","source":"* **MODEL 3** :  XGboost"},{"metadata":{"trusted":true,"_uuid":"529135553dccf68e02899c5e9ebb7196781f36af"},"cell_type":"code","source":"# m_3 <- caret::train(fare_amount ~ .,\n#     data = data_train,\n#     method = \"xgbTree\",\n#     metric = \"RMSE\",\n#     tuneLength = train_tuneLength,\n#     tuneGrid = expand.grid(nrounds = 20,\n#                             max_depth = train_depth,\n#                             eta = 0.05,\n#                             gamma = 0.005,\n#                             colsample_bytree = 0.75,\n#                             min_child_weight = 1,\n#                             subsample = 0.5),\n#     preProcess = PP,\n#     trControl = myControl\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67a0f3f01e5f5f7685f53be00dbe1d5bd9f7eb16"},"cell_type":"code","source":"# print(caret::varImp(m_3))\n# print(m_3)\n\n# results <- c(\"xgbTree\", m_3$results$RMSE, m_3$results$Rsquared, m_3$results$MAE)\n# model_results <- rbind(model_results, results)\n# print(na.omit(model_results))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba9b3c924dcb06594b11edd6bf0a8cc12fa9083"},"cell_type":"markdown","source":"**STEP 4 **: Blackboost Model"},{"metadata":{"trusted":true,"_uuid":"6af0f1a765bc7ba30bd2a15036592825a860ab1e"},"cell_type":"code","source":"m_4 <- caret::train(fare_amount ~ .,\n    data = data_train,\n    method = \"blackboost\",\n    metric = \"RMSE\",\n    tuneLength = train_tuneLength,\n    tuneGrid = expand.grid(mstop = c(60, 70, 80), \n                           maxdepth = train_depth),\n    preProcess = PP,\n    trControl = myControl\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"262db6f8124bf440f07098a7b39df32ac25f0dce"},"cell_type":"code","source":"print(caret::varImp(m_4))\nprint(m_4)\n\n# results <- c(\"blackboost\", m_4$results$RMSE, m_4$results$Rsquared, m_4$results$MAE)\n# model_results <- rbind(model_results, results)\n# print(na.omit(model_results))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e9551a1e03646f73459109498ee4240b4359df"},"cell_type":"markdown","source":"**STEP X **: asofijasdoif"},{"metadata":{"trusted":true,"_uuid":"a190f338ddd0b16d41bb3b9e0928563216823681"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a701611f2e4e914c11ec1f4eca6b9a8ea43d042c"},"cell_type":"code","source":"# train_keeps <- c(\"fare_amount\", \n#                   \"TRAVEL_TIME\", \n#                  \"SPEED\", \n#                  #\"longdiff_1\",\n#                  \"latdiff_1\", \n#                  \"longdiff_2\", \"latdiff_2\",\n#                  \"crowdist\", \n#                  \"bearing\",\n#                   \"month\", \"year\", \n#                   \"dow\",\n#                  #\"tod\",\n#                  \"hour\", \n#                   \"passenger_count\"\n#                 )\n\n# data_stack_train <- data_stack_train[train_keeps]\n\n# #PP <- c('pca', 'nzv', 'center', 'scale')\n# PP <- c('pca', 'nzv', 'medianImpute', 'center', 'scale')\n\n# folds <- 20 # 100 has worked best so far\n# repeats <- 5\n# myFolds <- createFolds(data_train, k = folds)\n# myGrid <- expand.grid(alpha = 0:1, lambda = seq(0.0001, 0.02, length = 10))\n\n# myControl <- trainControl(method = \"cv\", # cross validation of models (cv, boot, repeated_cv)\n#                           number = folds,\n#                           summaryFunction = defaultSummary,\n#                           #classProbs = TRUE, # IMPORTANT!\n#                           savePredictions = 'final',\n#                           verboseIter = FALSE,\n#                           allowParallel = TRUE,\n#                           index = createMultiFolds(data_train, k=folds, times=repeats) # For Stacks\n#                           )\n\n# print(\"caretList - model list\")\n# model_list_1 <- caretEnsemble::caretList(fare_amount ~ .,\n#                                        data = data_stack_train,\n#                                        trControl = myControl,\n#                                        preProcess = PP,\n#                                        continue_on_fail = FALSE,\n#                                        trace = FALSE,\n#                                        methodList = c(\n#                                            \"xgbTree\",\n#                                            \"blackboost\"\n# #                                            \"penalized\",\n# #                                             \"rlm\",\n# #                                            \"xgbLinear\",\n# #                                            \"ppr\"\n# # DOESNT WORK Well at this point --> \"svmRadial\"\n# # DOESNT WORK Well at this point --> \"glmnet\"\n# #  DOESNT WORK Well at this point --> \"knn\"\n# #  DOESNT WORK Well at this point --> \"gbm\"\n#                                                   #\"earth\",\n#                                                   #\"bagEarth\",\n#                                                   #\"gcvEarth\"\n#                                                   #\"parRF\",\n#                                                   #\"ranger\",\n#                                                   #\"spikeslab\",\n#                                                   #\n#                                         )\n#                                        )\n\n# resamples <- resamples(model_list_1)\n# stack <- caretEnsemble::caretStack(model_list_1, method = \"glmnet\")\n\n# print(summary(resamples))\n# print(stack)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d5652dd3dcc5ebac61cd0baa049878d3d47e06"},"cell_type":"markdown","source":"**Here's where the model comparison chart should go**"},{"metadata":{"trusted":true,"_uuid":"23b2c4efbbb054bd82d190a17ea8183f81ad23ae"},"cell_type":"code","source":"# print(str(model_results))\n# # hist(model_results$RMSE, model_results$model_list)\n# model_results <- round(na.omit(model_results),2)\n# # plot everything\n# ggplot(model_results, aes(model_list, RMSE)) +   \n#   geom_bar(aes(fill = r2), position = \"dodge\", stat = \"identity\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86f853e07570d1c2ab13cfcbc72522f4ad5c9fb9"},"cell_type":"markdown","source":"**SUBMISSION**"},{"metadata":{"trusted":true,"_uuid":"6bd225df69a7becdad4387c1c9cd13670347c5b9","scrolled":false},"cell_type":"code","source":"print(colSums(is.na(data_test)))\n\npredictions_1 <- predict(m_1, data_test)\npredictions_l1 <- predict(lm_1, data_test)\npredictions_2 <- predict(m_2, data_test)\n# predictions_3 <- predict(m_3, data_test)\npredictions_4 <- predict(m_4, data_test)\n\n# predictions_stack <- predict(stack, data_test)\n\npredictions <- (predictions_1 + predictions_l1 + predictions_2 + predictions_4) / 4\n# predictions <- predictions_1\n\nsub <- read.csv(\"../input/new-york-city-taxi-fare-prediction/sample_submission.csv\") %>%  \n         mutate(fare_amount = predictions)\n\nprint(head(sub, 20))\n\nwrite_csv(sub, \"submission_14th_12.csv\", append = FALSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17ec26317d0e0b2f3e17cb52f8e2fa1c936be36a"},"cell_type":"code","source":"print(\"SUBMITTING\")\nbeep(sound = 8, expr = NULL)\nprint(\":(\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43d3500a3d4e8c6ecd4d00d42b1d4ad7b10fb068"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"73d6c0e1954091476ff539323bfb469830ad735c"},"cell_type":"markdown","source":"Well... at least I had fun."}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}